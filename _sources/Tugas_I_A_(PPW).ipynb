{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hzr104v1Gjk"
      },
      "source": [
        "## Crawling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOzl2qRKrZ_L",
        "outputId": "7f01ecde-ba85-454c-8f72-1195602fe181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sprynger\n",
            "  Downloading sprynger-0.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sprynger) (5.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.32.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from sprynger) (2.5.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from sprynger) (4.3.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->sprynger) (2025.8.3)\n",
            "Downloading sprynger-0.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sprynger\n",
            "Successfully installed sprynger-0.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install sprynger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3TdU9CPrxSL",
        "outputId": "ea858820-fd81-42eb-f086-49c0c4f8886c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "HASIL UNTUK KATA KUNCI: WEB MINING\n",
            "================================================================================\n",
            "Total hasil: 317019\n",
            "\n",
            "DOI: 10.1007/978-3-032-00983-8_5\n",
            "Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets\n",
            "Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_7\n",
            "Title: Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis\n",
            "Abstract: Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.\n",
            "\n",
            "DOI: 10.1007/978-981-96-7238-7_2\n",
            "Title: Architecture Mining Approach for Systems-of-Systems: Monitoring and Discovery\n",
            "Abstract: Context: Systems of Systems (SoS) constitute a type of complex software systems resulting from integrating heterogeneous constituent systems that are independently operable on their own but are networked together for a common goal. Each constituent system has its own purpose and could operate and collaborate voluntarily with other constituent systems to achieve a common goal that cannot be treated by any of them in isolation. Objective: A constituent system may be deployed or undeployed at run-time within an SoS. Emergent behaviors may be undesirable and affect the behaviors of each constituent system and lead to unexpected operations and a lack of permanent status in the SoS. Thus, we need to continuously extract and represent the actual behaviors within the SoS at run-time. Method: In this paper, we implement the first step our “Architecture Mining” approach. Thus, we monitor an SoS and develop Discovery algorithm to extract the actual behaviors. The actual behaviors are presented by a “Discovered Model” dynamically and automatically built from the execution traces. Results: To implement our approach, we applied it to a case study entitled Smart City, which is an SoS including six types of constituent systems. We extracted the actual behaviors executed at run time from the SoS execution traces, which have never been modeled in any constituent system nor expected by the designer.\n",
            "\n",
            "DOI: 10.1007/978-3-031-95296-8_15\n",
            "Title: A Mathematical Model and Algorithm for Data Analysis in the Intelligent Management System for Mining and Transport Complexes\n",
            "Abstract: Machine learning methods play an important role in creating algorithms for data analysis in the mining industry. These methods allow you to train the system based on historical data and identify hidden patterns that may not be obvious in traditional analysis. Machine learning algorithms can be used to predict breakdowns, optimize production processes and identify anomalies in the operation of machinery. For example, with the help of training on data on the operation of equipment, you can create a model that will predict the probability of failure of a certain part under specified operating conditions.\n",
            "\n",
            "DOI: 10.1007/978-3-031-90470-7_6\n",
            "Title: ‘Internet of Things’ and ‘Social Networking’: Containment\n",
            "Abstract: Moving to the post-2000 period, or the post-formation Internet Polity, this chapter begins with the implications of the internet becoming the centred repository of sources, medium of investigation, and object in historicist accounts of recent and contemporary events. Debates on ‘technological determinism Technological determinism ’ are considered here. As events, 9/11 and the 2000 dot-com crash are pegged as turning points. A broad argument is proposed about the condition of the Internet Polity thereafter. It is suggested that it became contained in two moves during the 2000s. This containment involved, first, a space of the internet opening beyond the scope of the Internet Polity. This space incorporated data exchanges between ‘smart’ objects, unsupervised systems, and machine-learning systems. Second, much of the Internet Polity discourse and collective life became concentrated in very large platforms, which have global reach, local penetration, and data-management standards. This move facilitated the burgeoning data market and fed into the first move. The two moves are outlined by focusing on two catchwords and related terms. The first is addressed via the connotations of ‘Internet of Things’ and ‘smart’ objects, and the second by pausing on ‘social networking’ (on ‘sites’ or ‘platforms’). This chapter, and the study, concludes by briefly reconsidering the formative first principles of the Internet Polity, and pinpointing areas for further investigations.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_10\n",
            "Title: Integrating Graph Convolutional Networks for Web Traffic Prediction\n",
            "Abstract: Web traffic forecasting plays a crucial role in optimizing network resources, enhancing user experience, and ensuring efficient server load management. Traditional approaches, such as ARIMA, SARIMA, and machine learning methods like support vector machines and decision trees, focus primarily on temporal data. These models, however, often fail to capture the intricate relationships within web traffic data, such as user interactions or page-to-page connections, resulting in sub-optimal predictive performance. Graph Convolutional Networks (GCNs) address these limitations by modeling web traffic as a graph, where web pages or users are represented as nodes, and their interactions form edges. GCNs aggregate node information through graph structures, enabling the model to learn both spatial and temporal dependencies inherent in web traffic. This ability to exploit complex data relationships makes GCNs well-suited for more accurate and dynamic web traffic predictions. In this work, we propose a GCN-based framework for web traffic forecasting, incorporating multiple optimizers like Adam, RMSProp, and SGD to identify the model’s fair performance. By optimizing training through these methods, the GCN model efficiently captures both short-term fluctuations and long-term trends in web traffic patterns. Our study highlights the potential of GCNs in elevating the accuracy and reliability of web traffic forecasting. The integration of advanced optimizers further enhances convergence and prediction efficiency, offering a more scalable solution to meet the demands of rapidly growing and complex web systems.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93257-1_6\n",
            "Title: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\n",
            "Abstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_3\n",
            "Title: Leveraging Machine Learning Techniques for Customer Data Deduplication - Hard-Won Lessons from a Real-World Project in the Financial Industry\n",
            "Abstract: This paper is associated with a tutorial presented at DEXA 2025 Conferences and Workshops. The tutorial shares the practical experience gained from a 3-year R&D project for a big financial institution in Poland. The project aimed at developing deduplication pipelines for customer records. It involved the development of two distinct end-to-end deduplication pipelines that are based on (1) statistical/probabilistic modeling and on (2) machine learning. This tutorial focuses on lessons learned from developing the machine learning pipeline , within the context of a real-world industrial setting. Moreover, this tutorial provides an overview of approaches to data deduplication, including the traditional state-of-the-art baseline deduplication pipeline, solutions based on machine learning and neural networks that apply pre-trained and large language models.\n",
            "\n",
            "DOI: 10.1007/978-3-031-95296-8_21\n",
            "Title: Intelligent Control System for Ore Transportation and Grinding Process in Gold Mining Fields\n",
            "Abstract: This paper is devoted to optimizing the processes of work using intellectual control systems for the transportation and grinding of ore in gold mining fields. Ore is being optimized through the introduction of modern technologies and information systems in the transportation and grinding processes in order to increase efficiency, reduce energy consumption and reduce production costs. The paper examines the applications of IoT technologies, artificial intelligence, and large-scale data analysis in ore transport and grinding processes. With these systems, there is talk of monitoring processes in real time and improving the efficiency of equipment operation. New methods for managing ore transport and grinding processes through mathematical models, optimization algorithms and artificial neural networks are also presented. The results of scientific research in this paper can contribute to innovations and technological developments in the field of gold mining. Improving efficiency through automation of gold mining processes and intellectual management systems not only contributes to economic benefits, but also to the protection of the environment.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02088-8_29\n",
            "Title: Benchmarking Embedding Techniques for Modeling User Navigation Behavior on Task-Oriented Software\n",
            "Abstract: Understanding user navigation patterns from clickstream data is crucial for improving business software, yet remains challenging due to the complexity and variability of real-world environments. Unlike controlled settings, real-world clickstreams are noisy, fragmented, and often incomplete, due to session timeouts, network issues, caching, or third-party interactions—making it difficult to reconstruct coherent user journeys. Additionally, the absence of labeled data hinders the use of supervised learning, pushing researchers toward unsupervised or heuristic-based approaches that struggle to fully capture user behavior. In this paper, we present a benchmark of embedding techniques for modeling user navigation behavior on task-oriented software. We identify distinct user behaviors across three real-world case studies. Results show that Pattern2Vec outperforms Word2Vec in capturing meaningful task-based navigation patterns, confirming its suitability for clickstream analysis.\n",
            "\n",
            "DOI: 10.1007/978-3-031-85240-4_12\n",
            "Title: Predicting the Role of Temozolomide Drug in Glioma by Integrating Available Genomic Databases and Computational Methods\n",
            "Abstract: Cancer is one of the most serious and harmful diseases that threatens humanity. Currently there is no robust treatment which leads to guaranteed cure from cancer. Thus, researchers from various domains are still working hard to identify molecules such as genes and proteins which could be handled and targeted as cancer biomarkers. Various methods have been developed and the research spans wide range of techniques from wet lab testing by biologists to computational methods by computer scientists. The latter research is promising because it greatly reduces the number of molecules as potential biomarkers. This project investigated existing literature data by integrating text mining, as well as gene–gene interactions. Different genes are highlighted in relationship to Glioma and temozolomide.\n",
            "\n",
            "DOI: 10.1007/978-3-031-89518-0_1\n",
            "Title: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\n",
            "Abstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_7\n",
            "Title: An Enhanced FP-Growth Algorithm with Hybrid Adaptive Support Threshold for Association Rule Mining\n",
            "Abstract: Finding frequent itemsets remains challenging due to manual threshold specification requirements in existing algorithms. This paper presents an Enhanced FP-Growth algorithm incorporating a hybrid adaptive support threshold that combines statistical variance analysis, frequency distribution patterns, and transaction density metrics. The algorithm automatically adjusts support levels based on dataset characteristics, eliminating manual threshold tuning. Experimental evaluation on five benchmark datasets against Aprior, FP-growth, and FP-Max shows our Enhanced FP-Growth consistently achieves superior execution time and improved memory efficiency. The hybrid threshold mechanism dynamically calibrates according to dataset characteristics, offering substantial efficiency gains across diverse data types.\n",
            "\n",
            "DOI: 10.1007/978-981-96-2771-4_1\n",
            "Title: Research on Vulnerability Mining Technology of Electric Power Industrial Control Equipment Based on Genetic Algorithm\n",
            "Abstract: The traditional vulnerability mining methods for information systems require prior knowledge of protocol specifications, which often necessitates developers to invest significant time in learning and comprehending the protocol format for effective development of vulnerability mining test cases. However, in the power industry, industrial control equipment utilizes a multitude of private protocols with undisclosed specifications (unknown protocols). Consequently, the conventional vulnerability mining technology based on prior knowledge cannot be directly applied to these unknown industrial control protocols. To address this issue, this paper proposes a method and system of fuzzy testing for industrial control equipment based on genetic algorithms. The objective is to resolve challenges such as prolonged development periods, inability to test unknown protocols, and low efficiency in conducting vulnerability mining tests on unknown protocol vulnerabilities within industrial control equipment.\n",
            "\n",
            "DOI: 10.1007/978-3-032-00350-8_12\n",
            "Title: Ethical Implications of Using AI to Monitor and Regulate Dark Web Activities\n",
            "Abstract: The dark web continues to attract more illegal activities, and law enforcement and societal security face significant challenges. AI, though strong for monitoring and regulation, does raise critical ethical concerns concerning the use of these technologies for that purpose. This study considers the ethical aspects of AI systems for policing the dark web, including the trade-off between security and privacy, risks of bias and discrimination, and accountability in automated decision-making. Through a mixed-method approach involving both legal analysis, expert interviews, and case studies of existing AI-driven dark web monitoring systems, we identify central ethical challenges and potential mitigation strategies. In doing so, our results will reflect how AI may strengthen efficiency and effectiveness in terms of dark web policing, which equally result in the violation of user privacy, the perpetuation of systemic biases, and a lack of transparency in its operations. Ultimately, we conclude that proper use of AI in monitoring dark webs requires a robust governance framework, one that can ensure accountability, legitimacy, and respect for civil liberties. Such a framework must build on robust, clear guidelines for collecting and utilizing information, regular audits of bias, effectiveness, and mechanisms for human oversight and intervention. Given such measures, chances for using AI in the fight against crimes committed on the dark web are securely positioned within the right and constitutional means to protect the rights of individuals in this age of digitization.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_9\n",
            "Title: Citation Knowledge Graphs for Academic Insights: Modelling, Processing, and Analysis\n",
            "Abstract: The constant flow of information allows the data network to be accurately depicted as a graph, illustrating the interconnections across various groups, including items, customers, transactions, categories, reviews, and suppliers. Graph databases are proficient at revealing relationships and patterns in domains such as social networks, recommendation systems, the semantic web, and fraud detection. They facilitate intricate inquiries, including the determination of shortest paths, the identification of pivotal hubs, and the analysis of relationships. Although graph databases exhibit significant scalability and effectively handle extensive quantities of interconnected data, they frequently lack semantic Information, formal structure, and explicit typing. Knowledge graphs (KGs) mitigate these restrictions by structuring data in a graph format and linking data points via relationships to encapsulate Information. This chapter seeks to elucidate the functionalities of KGs, encompassing activities from traditional graph configurations to semantic frameworks, scalability issues, and query methodologies.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_29\n",
            "Title: Local-Aware Convolutional Modulation for Short-Term Sequential Recommendation\n",
            "Abstract: Sequential recommendation models have predominantly relied on self-attention mechanisms in recent years. However, beyond self-attention, other deep neural architectures such as convolutional neural networks (CNNs) offer promising alternatives for capturing sequential patterns. In this paper, we explore the CNN-based architecture and propose L ocal-aware C onvolutional M odulation for Short-Term Sequential Rec ommendation (LCMRec). Like other convolutional neural network-based models, LCMRec benefits from strong local modelling capabilities through its convolutional architecture. By introducing the multi-head convolutional modulation (MHCM) unit, which applies convolutions with varying kernel sizes across multiple heads locally, LCMRec dynamically captures short-term dependencies at multiple scales and keeps a linear computational complexity. In experiments, LCMRec outperforms baseline models, demonstrating the efficacy of the convolutional architecture and validating the effectiveness of our approach in balancing multi-scale dependency modelling with computational efficiency.\n",
            "\n",
            "DOI: 10.1007/978-3-032-01723-9_10\n",
            "Title: Geospatially-Informed Recommendations for Automobile Purchases: Integrating Spatial Analysis for Enhanced Decision-Making\n",
            "Abstract: This research proposes an integrated recommendation framework to support automobile purchase decisions by aligning consumer preferences with spatial and technical factors. In response to the challenges faced by car buyers, particularly those with limited automotive expertise and overwhelmed by excessive information, the model leverages sentiment analysis from social media and combines it with spatial variables, including dealership density, vehicle availability, circulation restrictions, environmental suitability, and pricing. These factors are then matched with technical specifications to generate personalized and context-aware vehicle suggestions. Using Mexico City as a case study, the empirical analysis reveals that regional differences in infrastructure, regulatory policies, economic conditions, and environmental constraints strongly shape vehicle preferences. The findings show that consumers in areas with stricter vehicle regulations and better service infrastructure tend to prefer vehicles with higher initial costs but lower long-term maintenance demands. While the system is built around the socio-economic and infrastructural peculiarities of Mexico City, it has been designed with modular and configurable components, allowing it to be adapted to international contexts with similar data availability. Nevertheless, the dependence on locally specific variables should be explicitly acknowledged when considering its broader applicability. This raises the question of scalability and transferability, inviting further research into how the framework can be generalized across diverse urban and regulatory environments.\n",
            "\n",
            "DOI: 10.1007/978-3-031-95296-8_14\n",
            "Title: Testing the Technology and Reliability of Using the Zigbee Network in Underground Mining Operations\n",
            "Abstract: In this scientific study, we explore the possibilities of using ZigBee technology in underground mining operations and examine its reliability. Our paper highlights the advantages and challenges of using ZigBee technology for signal transmission in underground environments, along with an evaluation of signal transmission range and stability based on test results. This research develops a mathematical model for transmitting employee position data via a ZigBee network. To enhance the reliability of the ZigBee network, we also consider the implementation of redundancy mechanisms (backup pathways) within the network.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93257-1_1\n",
            "Title: Time-Aware Recommendations with Motif-Enhanced Graph Learning\n",
            "Abstract: The time-aware recommendation model captures the dynamic evolution of user interests and item popularity by analyzing users’ historical behaviors, resulting in more accurate recommendations. Recent research has increasingly shifted from traditional sequential models to Graph Neural Networks to more effectively encode complex dynamic collaborative information. Despite these advances, many approaches often overlook important higher-order relations at the motif level and the spatial dynamics within graphs. In this work, we propose a novel time-aware recommendation method named MoDynRec ( Mo tif-Enhanced Dyn amic Graph Learning for Rec ommendations), which effectively models higher-order features and their spatiotemporal evolution by incorporating motifs into dynamic graph representation learning. The approach employs a two-fold strategy: (1) a motif-preserving structural encoder, which aggregates higher-order information from diverse motifs to retain critical structural patterns, and (2) an attention-based temporal encoder, which integrates multi-head self-attention mechanisms to capture sequential evolution patterns in the temporal dimension. This is further enhanced by dynamic graph convolution networks, which explore spatial correlations among nodes, improving adaptability to evolving relationships over time. Extensive experiments on two publicly available datasets demonstrate the effectiveness of the proposed model.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "HASIL UNTUK KATA KUNCI: WEB USAGE MINING\n",
            "================================================================================\n",
            "Total hasil: 90635\n",
            "\n",
            "DOI: 10.1007/978-3-031-90470-7_6\n",
            "Title: ‘Internet of Things’ and ‘Social Networking’: Containment\n",
            "Abstract: Moving to the post-2000 period, or the post-formation Internet Polity, this chapter begins with the implications of the internet becoming the centred repository of sources, medium of investigation, and object in historicist accounts of recent and contemporary events. Debates on ‘technological determinism Technological determinism ’ are considered here. As events, 9/11 and the 2000 dot-com crash are pegged as turning points. A broad argument is proposed about the condition of the Internet Polity thereafter. It is suggested that it became contained in two moves during the 2000s. This containment involved, first, a space of the internet opening beyond the scope of the Internet Polity. This space incorporated data exchanges between ‘smart’ objects, unsupervised systems, and machine-learning systems. Second, much of the Internet Polity discourse and collective life became concentrated in very large platforms, which have global reach, local penetration, and data-management standards. This move facilitated the burgeoning data market and fed into the first move. The two moves are outlined by focusing on two catchwords and related terms. The first is addressed via the connotations of ‘Internet of Things’ and ‘smart’ objects, and the second by pausing on ‘social networking’ (on ‘sites’ or ‘platforms’). This chapter, and the study, concludes by briefly reconsidering the formative first principles of the Internet Polity, and pinpointing areas for further investigations.\n",
            "\n",
            "DOI: 10.1007/978-3-032-00983-8_5\n",
            "Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets\n",
            "Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_7\n",
            "Title: Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis\n",
            "Abstract: Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_7\n",
            "Title: An Enhanced FP-Growth Algorithm with Hybrid Adaptive Support Threshold for Association Rule Mining\n",
            "Abstract: Finding frequent itemsets remains challenging due to manual threshold specification requirements in existing algorithms. This paper presents an Enhanced FP-Growth algorithm incorporating a hybrid adaptive support threshold that combines statistical variance analysis, frequency distribution patterns, and transaction density metrics. The algorithm automatically adjusts support levels based on dataset characteristics, eliminating manual threshold tuning. Experimental evaluation on five benchmark datasets against Aprior, FP-growth, and FP-Max shows our Enhanced FP-Growth consistently achieves superior execution time and improved memory efficiency. The hybrid threshold mechanism dynamically calibrates according to dataset characteristics, offering substantial efficiency gains across diverse data types.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93257-1_6\n",
            "Title: Adaptive Web API Recommendation via Matching Service Clusters and Mashup Requirement\n",
            "Abstract: With the rapid proliferation of Web services and Web APIs, recommendation systems can effectively address the issue of information overload and alleviate the burden of meaningless filtering. Existing approaches can help filtering appropriate Web services for mashup creation, however, they often fall short of developers’ different and personalized needs by recommending only a fixed number of APIs and lack precision in aligning mashup requirements across all categories. To solve the above issue, this paper introduces a novel Web service recommendation framework called AWAR for mashup creation, which focuses on the matching strategy between mashup requirements and Web APIs, and enhances recommendation effectiveness by integrating natural language processing, optimization algorithms, and deep learning. Extensive experiments conducted on large-scale real datasets demonstrate that the proposed approach receives superior recommendation results on multiple evaluation metrics compared to advanced competing baselines.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02088-8_29\n",
            "Title: Benchmarking Embedding Techniques for Modeling User Navigation Behavior on Task-Oriented Software\n",
            "Abstract: Understanding user navigation patterns from clickstream data is crucial for improving business software, yet remains challenging due to the complexity and variability of real-world environments. Unlike controlled settings, real-world clickstreams are noisy, fragmented, and often incomplete, due to session timeouts, network issues, caching, or third-party interactions—making it difficult to reconstruct coherent user journeys. Additionally, the absence of labeled data hinders the use of supervised learning, pushing researchers toward unsupervised or heuristic-based approaches that struggle to fully capture user behavior. In this paper, we present a benchmark of embedding techniques for modeling user navigation behavior on task-oriented software. We identify distinct user behaviors across three real-world case studies. Results show that Pattern2Vec outperforms Word2Vec in capturing meaningful task-based navigation patterns, confirming its suitability for clickstream analysis.\n",
            "\n",
            "DOI: 10.1007/978-3-032-01723-9_9\n",
            "Title: Analyzing Water Consumption Patterns in Mexico City: A GIS and Data Science Approach\n",
            "Abstract: Water scarcity in Mexico City has become an increasingly urgent issue, exacerbated by inefficient and unequal consumption patterns across its urban fabric. This study advances Geographic Information Systems (GIS) research by developing and applying an integrative spatial analysis framework specifically tailored to the complexities of urban water management. Beyond its application to Mexico City, the research demonstrates how GIS can be used to fuse heterogeneous datasets, including those from SACMEX (Mexico City’s Water System), INEGI (National Institute of Statistics and Geography), and DENUE (National Directory of Economic Units), into a unified analytical environment. Through a combination of exploratory data analysis (EDA), spatial data mining, and clustering techniques, the study identifies critical disparities in water consumption at multiple spatial scales, from boroughs to neighborhoods. A key contribution is the implementation of a layered system architecture for managing historic spatiotemporal data, enabling dynamic visualization of consumption patterns. The findings reveal that socio-economic and demographic variables play a decisive role in shaping spatial water demand, with marginalized communities facing disproportionate challenges. While previous spatiotemporal analyses of water consumption in Mexico City have primarily focused on aggregated borough-level data or isolated socio-demographic correlations, they have often lacked multiscale integration, high-resolution neighborhood-level analysis, or interactive visualization tools to support policy development. This research addresses these limitations by providing a fine-grained, multilayered analytical approach that enhances the scientific understanding of urban water use. Beyond offering immediate policy-relevant insights for Mexico City, the methodological framework proposed here contributes to GIS research by providing a scalable, transferable approach for analyzing urban resource consumption patterns. Future work will focus on incorporating real-time data streams, expanding sector-specific analysis, and integrating additional variables and domains required for a comprehensive understanding of water dynamics. This study represents a first step toward building an adaptive, equitable, and efficient urban water management strategy.\n",
            "\n",
            "DOI: 10.1007/978-981-96-6951-6_19\n",
            "Title: Research on Sensor Behavioral Psychological Health Based on Multi-task Learning\n",
            "Abstract: As society develops, mental health is becoming increasingly important. Traditional mental health assessment methods, such as face-to-face interviews and observational techniques, are limited by several factors, including subjectivity, response delays, and high costs. To address these issues, recent research has utilized smart sensor data. Using smartphones to collect data provides valuable insights into student behavior while ensuring the privacy of the individuals involved. The transition from traditional questionnaires to sensor data has prompted the adoption of a multi-task learning (MTL) framework for a more comprehensive classification of mental health. This study investigates the relationship between behavioral attributes and mental health dimensions, using the Apriori algorithm for association rule mining and feature extraction. This method uncovers significant correlations, highlighting the close connection between mental health and behavioral data through detailed analysis. The study proposes the use of multi-task modeling to optimize information utilization and identify correlations across tasks. The introduction of the Deep Cross Network with Squeeze and Excitation Network and Progressive Layered Extraction (DC-SE-PLE), a deep learning neural network model, enhances hierarchical feature extraction and cross-task learning, significantly improving the model’s generalization and prediction accuracy.\n",
            "\n",
            "DOI: 10.1007/978-3-031-89518-0_1\n",
            "Title: On the Centrality of Web Trackers: Assessing Its Potential for Automated Detection\n",
            "Abstract: For the past 20 years, web tracking has raised worries among privacy advocates and authorities responsible for data protection. Researchers have proposed several machine learning-driven remedies to identify Web trackers in an automated manner. While those have displayed potential, they have primarily remained as proofs-of-concept. This work extends on t.ex-Graph outlined in our previous work [ 36 ]. The aim of this model is to distinguish benign from tracking hosts by considering their centrality in the network, and data flows to them. Based on the results of our previous work, we abandoned the SLD-based approach. Consequently, we made slight modifications to the feature vector. Our classifier’s performance is comparable to its original version, and we tested its cross-browser and longitudinal performance. Our results indicate that while the cross-browser performance significantly decreases, the longitudinal performance maintains a high level.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_6\n",
            "Title: FNoDe: Faulty Node Detection in Microservices Architecture\n",
            "Abstract: As cloud services shift from monolithic architectures to microservices, post-failure fault and anomaly detection becomes increasingly challenging due to cascading effects across interdependent services and the overwhelming volume of heterogeneous logs and metrics. We propose FNoDe (Faulty Node Detection), a framework that integrates application logs, performance metrics, and distributed traces into a unified graph structure to detect both the root cause and type of anomaly. By leveraging a graph convolutional network (GCN), FNoDe learns system representations under normal and anomalous states from historical microservice data and uses these embeddings to classify new system states. Evaluated on five public benchmarks and two in-house microservice systems, FNoDe outperforms traditional methods by 20–30% in accuracy and maintains competitive performance with state-of-the-art frameworks, while also offering interpretability through XAI techniques.\n",
            "\n",
            "DOI: 10.1007/978-3-031-90470-7_5\n",
            "Title: The Vocabulary and Culture of Internet Collectivity\n",
            "Abstract: Taking a wider view, but still with a predominant focus on the 1990s, this chapter describes how a distinctive vocabulary for Internet Polity discourse developed and how cultural significance was attributed to collective activities on the internet. A brief discussion of the nodal term—‘internet’, and coterminously words with ‘e-’ and ‘digital’ prefixes—precedes that. An account of computing and internet dictionaries (and glossaries and word-listings) fleshes out the vocabulary that was consolidated as Internet Polity discourse. Several phases of dictionary making are covered: of computing terms for professionals, of computing terms for lay users, of hacker slang/jargon/techspeak, of internet terms in themselves, of internet slang Slang and cyberlexicography. Turning next to attributions of cultural collectivity via Internet Technology, the overlaps and distinction between Technoculture ‘technoculture’, ‘cyberculture Cyberculture ’, and ‘digital culture Digital culture ’ are unpacked. After pausing on the rise of popular ‘online communities’, a final section delineates the normative and ideological shifts that took place around the term ‘hacker’.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02049-9_20\n",
            "Title: DInos: A Deep Reinforcement Learning Approach to Generalizable Autoscaling in Stateless Cloud Applications\n",
            "Abstract: Efficient autoscaling in Kubernetes (K8s)-managed in-memory systems like Redis remains a critical challenge, especially under highly dynamic workloads. Traditional threshold-based mechanisms (e.g., HPA) often fail to anticipate sudden demand surges, leading to poor performance and inefficient resource use. We introduce DInos , a Deep Reinforcement Learning (Deep RL) agent enhanced with LSTM layers and transfer learning, designed for proactive and adaptive autoscaling in Kubernetes. As an evolution of our earlier agent DERP, DInos leverages temporal workload modeling and pre-trained policies to generalize across deployments with minimal retraining. DInos utilizes a customizable reward function balancing throughput, latency, resource usage, and pod efficiency. DInos achieves up to 17.3 $$\\times $$ × higher rewards in simulation and a 5.5 $$\\times $$ × improvement in real-world K8s-Redis deployments by forecasting spikes, optimizing pod counts and maintaining low latency, providing a robust autoscaling solution for volatile, cloud-native environments.\n",
            "\n",
            "DOI: 10.1007/978-3-032-00350-8_9\n",
            "Title: Enhanced Malicious URL Detection Through Feature Significance Analysis\n",
            "Abstract: Effective detection and classification of malicious URLs are critical components of safeguarding against cyber threats in today’s digital landscape. Malicious URLs serve as gateways for various cyber-attacks, including malware distribution, phishing attempts, defacement activities, and spam propagation. Detecting these malicious URLs requires advanced techniques that can analyze and distinguish between benign and harmful web entities. Machine learning (ML) algorithms have emerged as powerful tools in this endeavor, leveraging diverse feature categories and sophisticated classifiers to differentiate between legitimate and harmful URLs. In our study, we evaluated the performance of ML algorithms, with Random Forest achieving notable accuracy rates of 96.83% for binary classification and 92.13% for multi-classification, outperforming other classifiers. Our investigation spans Lexical, Content Analysis, Identity Verification, Identity Similarity, Visual Similarity, Behavioral Analysis, Entropy Analysis, and Geographic Analysis features. Our research seeks to provide comprehensive insights into the methodologies and approaches employed in malicious URL detection. This research adopts a systematic, manual process to identify and rank critical URL characteristics, ensuring relevance and interpretability. The findings provide comprehensive insights into malicious URL detection methodologies, highlighting effective strategies for both binary and multi-class classification tasks.\n",
            "\n",
            "DOI: 10.1007/978-3-031-99857-7_23\n",
            "Title: Scalable Compression of Massive Data Collections on HPC Systems\n",
            "Abstract: The exponential growth of digital data poses a significant storage challenge, straining current storage systems in terms of cost, efficiency, maintainability, and available resources. For large-scale data archiving, highly efficient data compression techniques are vital for minimizing storage overhead, communication efficiency, and optimizing data retrieval performance. This paper presents a scalable parallel workflow designed to compress vast collections of files on high-performance computing systems. Leveraging the Permute-Partition-Compress (PPC) paradigm, the proposed workflow optimizes both compression ratio and processing speed. By integrating a data clustering technique, our solution effectively addresses the challenges posed by large-scale data collections in terms of compression efficiency and scalability. Experiments were conducted on the Leonardo petascale supercomputer of CINECA (leonardo-supercomputer.cineca.eu), and processed a subset of the Software Heritage archive, consisting of about 49 million files of C++ code, totaling 1.1 TB of space. Experimental results show significant performance in both compression speedup and scalability.\n",
            "\n",
            "DOI: 10.1007/978-3-031-85240-4_24\n",
            "Title: 4WHContext: A Context Based Hate Speech Detection Framework from Social Media Posts\n",
            "Abstract: Detecting hate speech online has become increasingly important due to the surge in harmful content on social media. This is particularly challenging for resource-constrained languages like Bengali. This paper presents a dataset specifically created for detecting contextual hate speech in Bengali, developed through extensive data collection, preprocessing, and both manual and automatic labeling. It comprises 15,000 annotated texts categorized into hate speech and non-hate speech, with a Cohen’s kappa score of 0.88, reflecting strong agreement among annotators. We assessed the dataset using machine learning (ML), deep learning (DL), and BERT-based models. Among these, the BERT-based model XLM-R excelled, attaining an F1 score of 0.94 and an accuracy of 0.92 when context was considered, and an F1 score of 0.89 with an accuracy of 0.87 without context. These findings highlight that integrating context notably enhances the accuracy of hate speech detection, contributing to more effective methods for identifying and mitigating harmful online content.\n",
            "\n",
            "DOI: 10.1007/978-3-031-97141-9_20\n",
            "Title: ViMRHP: A Vietnamese Benchmark Dataset for Multimodal Review Helpfulness Prediction via Human-AI Collaborative Annotation\n",
            "Abstract: Multimodal Review Helpfulness Prediction (MRHP) is an essential task in recommender systems, particularly in E-commerce platforms. Determining the helpfulness of user-generated reviews enhances user experience and improves consumer decision-making. However, existing datasets focus predominantly on English and Indonesian, resulting in a lack of linguistic diversity, especially for low-resource languages such as Vietnamese. In this paper, we introduce ViMRHP ( Vi etnamese M ultimodal R eview H elpfulness P rediction), a large-scale benchmark dataset for MRHP task in Vietnamese. This dataset covers four domains, including 2K products with 46K reviews. Meanwhile, a large-scale dataset requires considerable time and cost. To optimize the annotation process, we leverage AI to assist annotators in constructing the ViMRHP dataset. With AI assistance, annotation time is reduced (90–120 seconds/task $$\\rightarrow $$ → 20–40 seconds/task) while maintaining data quality and lowering overall costs by approximately 65%. However, AI-generated annotations still have limitations in complex annotation tasks, which we further examine through a detailed performance analysis. In our experiment on ViMRHP, we evaluate baseline models on human-verified and AI-generated annotations to assess their quality differences. The ViMRHP dataset is publicly available at ( https://github.com/trng28/ViMRHP ).\n",
            "\n",
            "DOI: 10.1007/978-3-031-93580-0_8\n",
            "Title: Pathomorphological Diagnosis Process Intelligence\n",
            "Abstract: Business process management is oriented towards improving processes to best support people, who are working in them. Recent innovations in the area of artificial intelligence (AI), machine learning (ML), Internet of Things (IoT), and distributed systems have provided opportunities for new technologies applications, including process automation. This paper aims at the pathomorphological diagnosis (PD) process modeling for the ML solution implementation. The research method covers the PD laboratory case study. Authors argue that the PD process requires detailed analysis for its digitalization, automation, and combining with ML applications. Authors presented PD process models in BPMN notation, including laboratory equipment and emphasizing data and ML algorithms which are to be utilized in PD process digitalization for appropriate diagnosis for patients. Authors have found and emphasized that implementation of ML/AI algorithms is strongly based on fundamental process modeling.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_2\n",
            "Title: Data Integration in the AI Era: Research Trends and Still Open Issues\n",
            "Abstract: Data integration (DI) has been an area for intensive research for decades, which resulted in a few acknowledged reference architectures. The architectures can be categorized as supporting: (1) virtual integration (federated and mediated), (2) physical integration (data warehouse), and (3) hybrid (data lake, data lakehouse, data mesh). Regardless of their specific type, all these architectures rely on a complex integration layer. The layer is implemented by a sophisticated software, for designing, orchestrating, and running the so-called DI processes. On the one hand, in all business domains, large volumes of highly heterogeneous data are produced, e.g., medical systems, smart cities, smart agriculture, which require further advancements in the data integration technologies. On the other hand, the widespread adoption of artificial intelligence (AI) solutions is now extending towards DI, offering alternative solutions, opening new research paths, and generating new open problems. In this talk, I will share my perspective on the application and potential of AI solutions for selected DI problems. I will also highlight still unresolved issues within the field of DI. The talk will be structured into three main parts: (1) an overview of data integration architectures, (2) selected AI techniques for DI (like data wrangling, data quality, schema matching, optimization of systems, and code generation), and (3) still open problems in DI. The findings presented in the talk are based on my experience in running research and development DI projects for various business entities. It offers a concise overview of common DI challenges and potential solutions, serving as a quick-start guide for further exploration.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02088-8_5\n",
            "Title: ONFOODS: A Substitute Recommendation System in Food Recipes\n",
            "Abstract: Food waste is a serious problem in modern society. A specific aspect of food waste concerns meat consumption in gastronomy, where typically only prime cuts of meat are used in the kitchen. To facilitate the usage of all parts of animals and thereby reducing food waste, we present Onfoods , a system that recommends alternative meat cuts in recipes and integrates inventory data to help with the creation of menus. Onfoods uses an ontology and a knowledge graph to model recipes, meat cuts and the relationships between the two, similarity measures to find candidates for alternative meat cuts, and inventory data to track the availability of different meat cuts. An intuitive user interface allows the user on one hand to update the knowledge graph and inventory data, and on the other hand to navigate through recipes and choose alternative meat cuts.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02088-8_8\n",
            "Title: Efficient Source Selection for Federated SPARQL Queries Using Adjacent Predicate Information\n",
            "Abstract: With the growing adoption of Linked Open Data (LOD), many distributed knowledge bases have been developed using the RDF format. These knowledge bases each have unique characteristics, and querying across them can reveal richer and more comprehensive insights. To support such cross-repository querying, federated RDF query processing is essential. However, the performance of federated query execution largely depends on efficient source selection—the process of identifying which data sources are relevant to a given query. In this paper, we propose a novel source selection method for federated RDF queries based on a new summarization technique. Our approach precomputes the existence of shared elements between predicate pairs within each data source, considering three types of join patterns: subject–subject, subject–object, and object–object. These relationships are stored in a matrix-form summary for each data source. During query execution, our method identifies predicate pairs from triple patterns that share join keys within a basic graph pattern (BGP) and uses the precomputed summaries to efficiently determine the relevant data sources. Experimental results on the FedBench benchmark show that our method improves the efficiency of source selection and significantly reduces overall query execution time.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "HASIL UNTUK KATA KUNCI: DATA MINING\n",
            "================================================================================\n",
            "Total hasil: 1169861\n",
            "\n",
            "DOI: 10.1007/978-3-031-93530-5_1\n",
            "Title: Introduction\n",
            "Abstract: Many leading enterprises have started seeking opportunities to leverage advanced analytics on employee-related data to provide evidence-based insights into their workforce [65]. Among others, Google’s project “Oxygen” is an example of successfully deploying workforce analytics, which helped improve the company’s productivity and employee well-being and build up effective human resource management practices [40]. Yet, there are practical challenges that prevent workforce analytics from realizing its promise. One notable challenge is concerned with the absence of group-oriented analysis pivotal to strategy execution and organizational effectiveness [56]. For example, current workforce analytics has not yet enabled consistent comparisons across internal groups within organizations [44].\n",
            "\n",
            "DOI: 10.1007/978-3-032-00983-8_5\n",
            "Title: Survey on Data Mining and Machine Learning Methods Used in Analyzing Tweets\n",
            "Abstract: It is observed that the Mental illness by the actions and individual emotions and expressions towards a particular situation. It indicates that American Psychiatric Association that has 19% of people experience mental illness. Nearly 4.1% of people [ 1 ] are seriously affected by mental illness. In 2019, World Health Organization(WHO) reported that 264 million people suffer from mental disorders. With the technological growth and affordable internet access, social media usage and impacts are increased in society. Users use social networks to show their emotions, views, and comments related to mental health on various events and themselves. Different intelligent methods that analyze tweets related to depression are summarized. New research areas in analyzing data on social networks are discussed. This article highlights the data mining and machine learning methods associated with mental health using Twitter data.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02929-4_23\n",
            "Title: FairPM: A Taxonomy of Bias and Interventions in Process Mining\n",
            "Abstract: As organizations increasingly rely on data-driven methods to support decision-making, ensuring fairness in their processes becomes critical. Fairness in responsible process mining involves preventing unfair outcomes and recognizing potential biases that may arise in the different stages of process mining initiative. Acting fairly entails treating individuals equitably, irrespective of inherent or acquired characteristics such as gender, race, or disability, while ensuring compliance with legal and organizational fairness standards. While fairness in process mining has been explored in prior research, there remains a lack of conceptualization to identify, understand, and address fairness issues. To bridge this gap, we propose FairPM , a taxonomy that conceptualizes biases in process mining and the corresponding interventions to mitigate them. Our approach builds on theory adaptation as research method. It integrates an adaptation of biases and interventions from prior machine learning research into process mining. We illustrate the applicability of FairPM through three scenarios, demonstrating its relevance for both academia and industry. This research contributes to the growing field of fair process mining by providing a structured conceptualization that enables researchers and practitioners to diagnose biases and implement fairness interventions, ensuring equitable and unbiased process mining outcomes.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_5\n",
            "Title: Efficient Frequent Subgraph Mining: Algorithms and Applications in Complex Networks\n",
            "Abstract: Frequent subgraph mining (FSM) is a fundamental problem in graph analysis with wide-ranging applications in bioinformatics, social network analysis, cybersecurity, and cheminformatics. This paper presents efficient algorithms for FSM in complex networks, addressing the computational challenges posed by large-scale graph data. Traditional approaches often suffer from scalability issues due to the combinatorial explosion of subgraph candidates. To mitigate these challenges, we propose an optimized FSM framework leveraging advanced pruning techniques, graph compression, and parallel computing. Our approach incorporates pattern-growth strategies with heuristic search methods to improve computational efficiency while maintaining accuracy. We evaluate our proposed algorithms on benchmark datasets, demonstrating significant performance gains over existing methods in terms of runtime and memory consumption. Additionally, we explore real-world applications, such as detecting anomalous patterns in cybersecurity networks, identifying molecular structures in drug discovery, and analyzing connectivity patterns in social networks. The results underscore the potential of efficient FSM algorithms in extracting meaningful insights from complex graph data. This research contributes to the advancement of graph mining techniques, providing a scalable and effective solution for large-scale network analysis. Future work will explore deep learning-based enhancements to further optimize FSM in dynamic and evolving graph structures.\n",
            "\n",
            "DOI: 10.1007/978-3-032-00983-8_6\n",
            "Title: Optimizing Powder Factor for Sustainable Mining Operations Through Machine Learning Models: A Step Towards Intelligent Mining\n",
            "Abstract: This research addresses the challenge of optimizing the powder factor (PF) in mining operations to enhance blasting efficiency and sustainability. Machine learning models, including Linear Regression (LR), Random Sample Consensus (RANSAC), and Huber Regressor (HR), were employed to develop a predictive framework for PF optimization. Model performance was evaluated using metrics such as R^2 (0.9829 for LR, 0.9827 for RANSAC, and 0.9824 for HR), Mean Absolute Error (MAE), and Root Mean Square Error (RMSE), demonstrating their high predictive accuracy. The findings highlight the capability of machine learning to improve blasting control, reduce environmental impacts, and promote sustainable mining practices. By integrating artificial intelligence into mining operations, this study advances the concept of intelligent mining, offering innovative solutions that enhance operational efficiency while fostering environmental stewardship.\n",
            "\n",
            "DOI: 10.1007/978-3-031-96841-9_2\n",
            "Title: Analyzing Side-Tracking of Developers Using Object-Centric Process Mining\n",
            "Abstract: Managers need to analyze the software development process to pro-actively make decisions that meet quality, budget and time objectives. To aid this analysis, a number of data-driven approaches exist, which can be used for specific purposes, such as computing target key performance indicators (KPIs). In particular, process analysis techniques, like process mining, can analyze data from event logs of information systems and deliver actionable insights on how the process is conducted. However, traditional process mining techniques make strong assumptions on the structure of event logs, requiring the existence of a case identifier, used to group the traces. As a result, the output of such techniques only provides a narrow view of the reality, leading the manager towards wrong interpretations in cases of side-tracking , when a developer is involved in different processes that interleave one another. To account for these cases, we investigate the use of object-centric process mining (OCPM) to analyze software repositories. Our results help to explain performance issues by revealing the contributing factors that hinder the progress of development tasks.\n",
            "\n",
            "DOI: 10.1007/978-3-031-98033-6_6\n",
            "Title: Trustworthy Artificial Neural Networks Due to Process Mining in AI: Challenges and Opportunities\n",
            "Abstract: Although there has been a lot of progress in developing Process Mining (PM) algorithms and Artificial Intelligence (AI) techniques in recent years, no effort has been put in developing a common means of mining knowledge-based behavior of Artificial Neural Networks (ANN). In a design-science-oriented way, in this paper, elements of a new kind of AI-PM approach are outlined and demonstrated with ANN. These intend to enable (1) AI engineers to mine an ANN’s inner processes to discover its knowledge-induced behavior, realize conformance checking, e.g. w.r.t. an ANN required behavior, and improve ANN due to enhancement. To illustrate the application of this new approach, a set of novel model views and algorithms are proposed, which are demonstrated on simple example logs. Findings show that AI-PM supports the clarification of ANN behavior: As the ANN’s inner activities and knowledge generation can be mined, its non-transparent black box is unveiled and trustworthiness of ANN is supported.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93601-2_20\n",
            "Title: Leveraging General Unary Hypotheses Automaton for Automating Technical Analysis: A Case Study on Bitcoin Prices\n",
            "Abstract: This paper explores the application of the General Unary Hypotheses Automaton (GUHA) framework to automate the principles of technical analysis, focusing on Bitcoin price prediction. By leveraging technical indicators, such as the Relative Strength Index (RSI), Average Directional Index (ADX), and Bollinger Bands, this study employs data mining techniques to automate insights from technical analysis. The 4 ft-Miner and CF-Miner procedures, implemented through the CleverMiner Python framework, were applied to Bitcoin price data spanning from 2014 to 2024. The findings demonstrate the effectiveness of GUHA in identifying robust predictive patterns. Rules mined via 4 ft-Miner achieved 80.65% confidence in predicting next-day price decreases and 96.15% confidence in forecasting significant upward movements (next-day high exceeding a 1% increase over the opening price). CF-Miner further categorized price return probabilities, enhancing interpretability and revealing ordered insights into the prediction of positive returns. These results underscore GUHA’s potential to automate and enhance the efficiency of technical analysis, providing actionable intelligence for automated trading and financial risk management. By offering interpretable patterns and statistically significant relationships, the GUHA framework bridges the gap between traditional technical analysis and modern algorithmic trading strategies. Future research may extend this approach to longer-term trend predictions and multi-asset portfolios, further advancing the automation of financial market analysis.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93598-5_20\n",
            "Title: Boosting the Discovery of Interval Patterns Using SAT\n",
            "Abstract: Declarative pattern mining has seen significant advancements in recent years, particularly through the application of symbolic AI techniques on various data types, including binary, numerical, and graph data, etc. The core idea behind these approaches is to reformulate the task of pattern mining as a model enumeration problem in classical logic. These methods have been developed for their flexibility, allowing for easier incorporation of additional user constraints during the mining process. In this paper, we first present a symbolic approach for enumerating closed interval patterns using the propositional satisfiability problem (SAT). Then, by extending the SAT-based encoding of classical patterns with additional constraints to eliminate redundancy, our method proves to be highly efficient. Finally, experimental evaluations on various datasets demonstrate that our SAT-based framework is highly competitive with state-of-the-art approaches, even on large numerical databases.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02515-9_21\n",
            "Title: In Search of Digital Talent: Evidence from Public Sector Job Advertisements in Germany Using LLM-Enabled Competence Classification\n",
            "Abstract: The public sector continues to struggle with the digital transformation of its organizations, lagging behind the private sector in implementing digital processes and services. A key success factor is the availability of appropriate digital skills in the workforce. This can be enhanced by training existing staff or hiring skilled individuals. In the latter scenario, the hiring process must focus on the required competencies. Typically, job advertisements are used to communicate job requirements. his article explores the presence of digital competencies in job ads of German public organizations. We operationalize the DigComp 2.2 framework as a category system to identify required digital competences in these job advertisements. To assess a large volume of job postings, we employ a Large Language Model (LLM) for categorization. In this way, we are able to process 5,949 job advertisements. Results indicate frequent mentions of skills related to digital content creation and data handling, while communication, problem-solving, and safety are rarely highlighted. Although the reasons for this are not explicitly identified in our study, a mismatch is evident between the push for digital transformation in the public sector and the recruitment practices reflected in job advertisements.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02929-4_18\n",
            "Title: Predicting Newcomer Capabilities and Performance in Process Execution\n",
            "Abstract: Companies are constantly hiring new employees. To efficiently allocate these newcomers to tasks, we need to predict which tasks they can do and how well they will perform on these tasks. However, making such predictions for newcomers is challenging, particularly at the early stage of onboarding, due to the limited availability of observational data on their past experience. In this research, we explore the problem of predicting newcomer capabilities and performance in the context of process execution and propose a solution to address the challenge. The proposed approach uses data augmentation from historical event data, guided by organizational model mining, and generates predictions for the tasks that newcomers may perform and the time it will take them to perform those tasks. Experiments based on several real-life event logs showed that the proposed approach achieves accurate predictions for newcomers given limited data availability.\n",
            "\n",
            "DOI: 10.1007/978-3-031-95296-8_15\n",
            "Title: A Mathematical Model and Algorithm for Data Analysis in the Intelligent Management System for Mining and Transport Complexes\n",
            "Abstract: Machine learning methods play an important role in creating algorithms for data analysis in the mining industry. These methods allow you to train the system based on historical data and identify hidden patterns that may not be obvious in traditional analysis. Machine learning algorithms can be used to predict breakdowns, optimize production processes and identify anomalies in the operation of machinery. For example, with the help of training on data on the operation of equipment, you can create a model that will predict the probability of failure of a certain part under specified operating conditions.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02215-8_7\n",
            "Title: An Enhanced FP-Growth Algorithm with Hybrid Adaptive Support Threshold for Association Rule Mining\n",
            "Abstract: Finding frequent itemsets remains challenging due to manual threshold specification requirements in existing algorithms. This paper presents an Enhanced FP-Growth algorithm incorporating a hybrid adaptive support threshold that combines statistical variance analysis, frequency distribution patterns, and transaction density metrics. The algorithm automatically adjusts support levels based on dataset characteristics, eliminating manual threshold tuning. Experimental evaluation on five benchmark datasets against Aprior, FP-growth, and FP-Max shows our Enhanced FP-Growth consistently achieves superior execution time and improved memory efficiency. The hybrid threshold mechanism dynamically calibrates according to dataset characteristics, offering substantial efficiency gains across diverse data types.\n",
            "\n",
            "DOI: 10.1007/978-3-031-91058-6_2\n",
            "Title: Preliminaries\n",
            "Abstract: Blockchain systems are global-scale peer-to-peer systems that integrate many techniques and protocols from cryptography, distributed systems, and databases. In a blockchain system, nodes agree on their shared states across a large decentralized network of possibly untrusted participants. Bitcoin and other cryptocurrencies are permissionless blockchain systems. In permissionless blockchain systems, computing nodes without a priori known identities can join or leave the blockchain network at any time. On the other hand, a permissioned blockchain system uses a network of a priori known and identified nodes to manage the blockchain. While the focus of this monograph is on permissioned blockchains, in this chapter, we present preliminary concepts and techniques used in both permissionless and permissioned blockchains.\n",
            "\n",
            "DOI: 10.1007/978-3-032-01475-7_13\n",
            "Title: Pattern Mining Under Simon’s Congruence\n",
            "Abstract: Given two strings  u and v and an integer  k , we say u and v are Simon’s congruent with respect to k if they have the same set of subsequences of length at most k . We study the complete pattern mining problem for Simon’s congruence, where the problem is to find the substrings of a given text  $$\\texttt{T}$$ T that maximizes the number of congruent substrings of the text, for each possible value of k . We design new data structures that capture the equivalence classes with respect to $$\\sim _k$$ ∼ k for substrings of the text. We then propose an $$O(|\\texttt{T}|^2\\log ^2|\\texttt{T}|)$$ O ( | T | 2 log 2 | T | ) -time algorithm for fixed-sized alphabets using the new data structures.\n",
            "\n",
            "DOI: 10.1007/978-981-95-1331-4_21\n",
            "Title: Overview of Smart Cloud Gateway\n",
            "Abstract: With the rapid development of cloud computing and Internet of Things (IoT) technology, intelligent cloud gateway emerges as a key hub connecting end devices and cloud services. This paper elaborates the background, concepts and definitions of the emergence of intelligent cloud gateway, and discusses in depth its main technical capabilities, including data acquisition and processing, protocol conversion, security protection and other aspects. Meanwhile, it analyzes the industrial status quo of intelligent cloud gateway, covering market size, major vendors, etc., and looks forward to its future development trend. By comprehensively citing and analyzing the related literature, it provides a comprehensive reference for the research and application of intelligent cloud gateway.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93802-3_7\n",
            "Title: Unveiling Power Laws in Graph Mining: Techniques and Applications in Graph Query Analysis\n",
            "Abstract: Power laws play a crucial role in understanding the structural and functional properties of real-world graphs, influencing various aspects of graph mining and query processing. This paper explores the prevalence of power-law distributions in large-scale graph structures and their implications for graph query analysis. We investigate techniques for efficiently mining graphs that exhibit power-law characteristics, leveraging these distributions to optimize query performance and scalability. Our study presents a comprehensive review of existing methodologies for detecting power-law behavior in graphs, highlighting their impact on graph traversal, indexing, and query execution. We also examine algorithmic optimizations tailored for power-law graphs, including degree-based indexing, community-aware search techniques, and efficient subgraph matching approaches. Furthermore, we discuss the applications of power-law principles in diverse domains such as social network analysis, bioinformatics, and knowledge graphs. Through empirical analysis on real-world datasets, we demonstrate how power-law-aware techniques improve query efficiency and reduce computational complexity in large graph databases. The findings of this study offer valuable insights into the interplay between graph topology and query optimization, paving the way for enhanced graph mining frameworks. Our work contributes to the development of more scalable and intelligent graph query processing systems, with broad implications for data-driven decision-making.\n",
            "\n",
            "DOI: 10.1007/978-3-032-02049-9_3\n",
            "Title: A Hybrid Data Model to Support Transportation Analytics of Emergency Service Vehicles\n",
            "Abstract: Using a single type of database solution to support real-world applications is becoming more and more challenging because of the volume and variety of data. For instance, the data collected for the transportation industry comprise both structured and unstructured data. Using solely a single type of database solution—relational database system-only or graph database-only—to store and manage data can be challenging. As real-world applications ask even more complex questions related to data, the database solution should be able to facilitate answering these questions in a reasonable time. Hence, in this paper, we present a hybrid model, which integrates data to support transportation analytics. The model consists of relational databases and non-relational databases (namely, graph databases), pooling their strengths to support the demands of the modern application. We also demonstrate this hybrid data model as a practical solution with a case study on improving emergency services—such as emergency medical services (EMS)—response times by having the support of the presented platform.\n",
            "\n",
            "DOI: 10.1007/978-3-031-93601-2_21\n",
            "Title: Data Science Techniques for Opinion Mining in Industrial Applications\n",
            "Abstract: Opinion mining is a crucial research area in data science that focuses on the automatic analysis of textual data (such as reviews, customer comments, and feedback) to identify and evaluate sentiments expressed. In industrial contexts, it plays a vital role in enhancing customer feedback analysis, optimizing predictive maintenance, and improving process efficiency. In this research, we propose an innovative opinion mining method that combines Natural Language Processing (NLP), domain ontologies, and Machine Learning (ML) techniques to assist managers in making informed decisions about their products and services. Our method begins by constructing domain-specific ontologies, which play a key role in aspect detection within user comments. We then collect a raw dataset from social media platforms, such as YouTube and Facebook, focusing on four domains: Tunisian restaurants, smartphones, the 2019 Tunisian elections, and Tunisian TV programs. This dataset undergoes multiple pre-processing steps, including transliteration, stop-word removal, and vectorization, to prepare it for analysis. To classify sentiments, we employ two advanced deep learning models (i.e., LSTM and Bi-GRU), which are applied to analyze both the overall sentiment of each comment and the sentiment associated with specific aspects. This dual-layer analysis provides a detailed understanding of user opinions, identifying whether sentiments are positive, negative, or neutral at both the comment and aspect levels. This work not only advances the field of opinion mining through the integration of ontologies and deep learning but also offers valuable practical implications for decision-making in a wide range of industrial applications.\n",
            "\n",
            "DOI: 10.1007/978-981-95-1337-6_5\n",
            "Title: Research on Abnormal Identification Technology of Network Traffic Data in Power Monitoring System\n",
            "Abstract: With the strengthening of the power system construction, the power information network and the service system it carries have been developed rapidly. Although a large number of encrypted data packets are currently being transmitted, existing network traffic analysis techniques cannot effectively identify these packets, resulting in the omission of many important features during the monitoring process. This not only increases the probability of false positives and false negatives, but also provides useful space for criminals. To address this issue, it is necessary to conduct online analysis of full traffic and dynamically identify anomalies. We develop a new method for flow analysis and anomaly detection in power monitoring systems. This method adopts different detection strategies based on whether network traffic is encrypted, to achieve comprehensive monitoring of network attack behavior.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Masukkan API key dari Springer\n",
        "api_key = \"bb5c8dcf4c49724ba77086b237793f86\"\n",
        "\n",
        "# Daftar kata kunci\n",
        "keywords = [\"web mining\", \"web usage mining\", \"data mining\"]\n",
        "\n",
        "# URL Springer API\n",
        "url = \"https://api.springernature.com/meta/v2/json\"\n",
        "\n",
        "# List untuk menyimpan semua hasil agar bisa di-export ke CSV\n",
        "all_results = []\n",
        "\n",
        "for keyword in keywords:\n",
        "    print(\"=\"*80)\n",
        "    print(f\"HASIL UNTUK KATA KUNCI: {keyword.upper()}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    params = {\n",
        "        \"q\": keyword,\n",
        "        \"api_key\": api_key,\n",
        "        \"p\": 20\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        total = data[\"result\"][0][\"total\"]\n",
        "        print(f\"Total hasil: {total}\\n\")\n",
        "\n",
        "        for record in data[\"records\"]:\n",
        "            doi = record.get(\"doi\", \"N/A\")\n",
        "            title = record.get(\"title\", \"No title\")\n",
        "            abstract = record.get(\"abstract\", \"No abstract\")\n",
        "            publication = record.get(\"publicationName\", \"N/A\")\n",
        "            url_val = record.get(\"url\", [{\"value\":\"N/A\"}])[0][\"value\"]\n",
        "\n",
        "            # Tampilkan ke console\n",
        "            print(f\"DOI: {doi}\")\n",
        "            print(f\"Title: {title}\")\n",
        "            print(f\"Abstract: {abstract}\\n\")\n",
        "\n",
        "            # Simpan ke list untuk CSV\n",
        "            all_results.append({\n",
        "                \"keyword\": keyword,\n",
        "                \"doi\": doi,\n",
        "                \"title\": title,\n",
        "                \"abstract\": abstract\n",
        "            })\n",
        "\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "\n",
        "    print(\"\\n\\n\")  # pemisah antar keyword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oii273swy2Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f410bf1e-e105-4c4c-ac7b-70627bfc8389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Semua hasil sudah disimpan di file hasil_crawling.csv (total 60 record)\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(all_results)\n",
        "df.to_csv(\"hasil_crawling.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"✅ Semua hasil sudah disimpan di file hasil_crawling.csv (total {len(all_results)} record)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}